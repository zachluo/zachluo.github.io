<html>

<head>
<title>Weixin Luo's home page</title>
<style type="text/css" media="screen">
html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p,
blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em,
font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt,
dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot,
thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}

a {
  color: #1772d0;
  text-decoration:none;
}

a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}

a.paper {
  font-weight: bold;
  font-size: 12pt;
}

b.paper {
  font-weight: bold;
  font-size: 12pt;
}

* {
  margin: 0pt;
  padding: 0pt;
}

body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 800px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #eee;
}

h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15pt;
  font-weight: 700;
}

h4 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13pt;
  font-weight: 700;
}

h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  font-weight: 700;
}

strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
}

ul {
  list-style: circle;
}

img {
  border: none;
}

li {
  padding-bottom: 0.5em;
  margin-left: 1.4em;
}

strong, b {
	font-weight:bold;
}

em, i {
	font-style:italic;
}

div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}

div.spanner {
  clear: both;
}

div.paper {
  clear: both;
  margin-top: 0.3em;
  margin-bottom: 0.3em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}

div.paper div {
  padding-right: 230px;
}

div.paper div.wide {
  padding-right: 0px;
}

img.paper {
  margin-bottom: 0.5em;
  float: right;
  width: 200px;
}

span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}

pre, code {
  font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
  margin: 1em 0;
  padding: 0;
}

div.paper pre {
  font-size: 0.9em;
}

</style>

<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-142476783-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?41c80192f6292fc7f24bf102a96e87d4";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
	

<script type="text/javascript" src="js/hidebib.js"></script>

<link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic"
 rel="stylesheet" type="text/css" />
</head>

<body>

<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 200px;">
  <div style="margin: 0 auto; width: 70%; line-height: 130%;">
    <img title="rbg" style="float: right; padding-right: .5em; height: 200px;" src="images/luowx.jpg" />
    <div style="padding-left: 1em; vertical-align: top; height: 250px;">
      <span style="font-size: 16pt; line-height: 130%;">Weixin Luo</span><br />
      <span>Ph.D</span><br />
      <a href="https://scholar.google.com/citations?user=1Gpoj9MAAAAJ&hl=en" target="_blank">Google scholar</a>
    </div>
  </div>
</div>

<div style="clear: both;"><!-- page div -->

<div class="section">
<h2>About me</h2>
  <div class="paper">
    I am now working at Meituan. I received my Ph.D. degree from ShanghaiTech University in 2020, supervised by <a href="https://scholar.google.com/citations?user=fe-1v0MAAAAJ&hl=en">Shenghua Gao</a>. I worked with <a href="https://pages.cs.wisc.edu/~yongjaelee/" target="_blank">Yong Jae Lee</a> at University of California, Davis. I received my BEng. Degree from Shenzhen University in 2015.
  </div>
</div>

<div class="section">
<h2> Recent News </h2>
	<div class="paper">
		<ul>
			[2022-10] We rank No.1 on the <a href="https://kaldir.vc.in.tum.de/scanrefer_benchmark/benchmark_localization">ScanRefer</a> Challenge at ECCV 2022.	
		</ul>
		<ul>
			[2022-10] We rank No.1 (hand action) and No.2 (hand pose) on the H2O Challenge at ECCV 2022.	
		</ul>
		<ul>
			[2022-03] One paper was accepted by CVPR 2022.	
		</ul>
		<ul>
			[2021-11] One paper was accepted by AAAI 2022.	
		</ul>
	</div>
</div>

<div class="section">
<h2 id="reports">Selected Publications</h2>
  <!--------------------------------------------------------------------------->
  <!--luo2022ham-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luo2022ham">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luo2022ham']);" href="https://arxiv.org/pdf/2210.12513.pdf">HAM: Hierarchical Attention Model with High Performance for 3D Visual Grounding</a><br />
      Jiaming Chen*, <strong>Weixin Luo*</strong>, Xiaolin Wei, Lin Ma, Wei Zhang<br />
      Arxiv 2022 /
      <a href="https://github.com/PPjmchen/HAM">code</a>
    </div>
  </div>
  <!--------------------------------------------------------------------------->		

  <!--------------------------------------------------------------------------->
  <!--luo2022oad-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luo2022oad">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luo2022oad']);" href="https://arxiv.org/pdf/2208.14209.pdf">A Circular Window-based Cascade Transformer for Online Action Detection</a><br />
      Shuqiang Cao*, <strong>Weixin Luo*</strong>, Bairui Wang, Wei Zhang, Lin Ma <br />
      Arxiv 2022 
    </div>
  </div>
  <!--------------------------------------------------------------------------->	

  <!--------------------------------------------------------------------------->
  <!--luo2022cvpr-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luo2022cvpr">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luo2022cvpr']);" href="https://openaccess.thecvf.com/content/CVPR2022/papers/Qian_SVIP_Sequence_VerIfication_for_Procedures_in_Videos_CVPR_2022_paper.pdf">SVIP: Sequence VerIfication for Procedures in Videos</a><br />
      Yicheng Qian, <strong>Weixin Luo</strong>, Dongze Lian, Xu Tang, Peilin Zhao, Shenghua Gao<br />
      CVPR 2022 /
      <a href="https://github.com/svip-lab/SVIP-Sequence-VerIfication-for-Procedures-in-Videos">code</a>
    </div>
  </div>
  <!--------------------------------------------------------------------------->
	
  <!--------------------------------------------------------------------------->
  <!--luo2022aaai-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luo2022aaai">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luo2022aaai']);" href="https://www.aaai.org/AAAI22Papers/AAAI-2108.ChenJ.pdf">Explore Inter-Contrast Between Videos via Composition for Weakly Supervised Temporal Sentence Grounding</a><br />
      Jiaming Chen*, <strong>Weixin Luo*</strong>, Wei Zhang, Lin Ma<br />
      AAAI 2022 /
      <a href="https://github.com/PPjmchen/Composition_WSTG">code</a>
    </div>
  </div>
  <!--------------------------------------------------------------------------->
	
	
  <!--------------------------------------------------------------------------->
  <!--luo2021tpami-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luo2021tpami">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luo2021tpami']);" href="https://ieeexplore.ieee.org/document/9622181">Future Frame Prediction Network for Video Anomaly Detection</a><br />
      <strong>Weixin Luo*</strong>, Wen Liu*, Dongze Lian, Shenghua Gao<br />
      TPAMI 2021 
    </div>
  </div>
  <!--------------------------------------------------------------------------->
	
  <!--------------------------------------------------------------------------->
  <!--lian2021tpami-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="lian2021tpami">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'lian2021tpami']);" href="https://ieeexplore.ieee.org/document/9601215">Locating and Counting Heads in Crowds With a Depth Prior
</a><br />
      Dongze Lian, Xianing Chen, Jing Li, <strong>Weixin Luo</strong>, Shenghua Gao<br />
      TPAMI 2021 /
      <a href="https://github.com/svip-lab/Locating_Counting_with_a_Depth_Prior"> code </a>
    </div>
  </div>
  <!--------------------------------------------------------------------------->
	
 <!--------------------------------------------------------------------------->
  <!--luo2020nips-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luo2020nips">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luo2020nips']);" href="https://arxiv.org/abs/2010.14301">SIRI: Spatial Relation Induced Network For Spatial Description Resolution</a><br />
      Peiyao Wang*, <strong>Weixin Luo*</strong>, Yanyu Xu, Haojie Li, Shugong Xu, Jianyu Yang, Shenghua Gao<br />
      NeurIPS 2020
    </div>
  </div>
  <!--------------------------------------------------------------------------->

  <!--------------------------------------------------------------------------->
  <!--luo2020eccv-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luo2020eccv">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luo2020eccv']);" href="https://arxiv.org/pdf/1911.11759.pdf">Password-conditioned Anonymization and Deanonymization with Face Identity Transformers</a><br />
      Xiuye Gu, <strong>Weixin Luo</strong>, Michael S. Ryoo, Yong Jae Lee<br />
      ECCV 2020 /
      <a href="https://github.com/laoreja/face-identity-transformer"> code </a>
      
    </div>
  </div>
  <!--------------------------------------------------------------------------->

  <!--------------------------------------------------------------------------->
  <!--luo2019pami-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luo2019pami">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luo2019pami']);" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8851288">Video Anomaly Detection with Sparse Coding Inspired Deep Neural Networks</a><br />
      <strong>Weixin Luo*</strong>, Wen Liu*, Dongze Lian, Jinhui Tang, Lixin Duan, Xi Peng, Shenghua Gao<br />
      TPAMI 2019 (sci highly cited paper) /
       <a href="https://github.com/StevenLiuWen/sRNN_TSC_Anomaly_Detection"> code </a>
    </div>
  </div>
  <!--------------------------------------------------------------------------->
  
  <!--------------------------------------------------------------------------->
  <!--luo2019ijcai-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luo2019ijcai">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luo2019ijcai']);" href="https://www.ijcai.org/proceedings/2019/0419.pdf">Large Margin Video Anomaly Detection with A Few Anomalies</a><br />
      Wen Liu*, <strong>Weixin Luo*</strong>, Shenghua Gao.<br />
      IJCAI 2019 /
      <a href="https://github.com/svip-lab/MLEP"> code </a>
    </div>
  </div>
  <!--------------------------------------------------------------------------->
  
  <!--------------------------------------------------------------------------->
  <!--luowx2019cvpr1-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luowx2019cvpr1">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luowx2019cvpr1']);" href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Lian_Density_Map_Regression_Guided_Detection_Network_for_RGB-D_Crowd_Counting_CVPR_2019_paper.pdf">Density Map Regression Guided Detection Network for RGB-D Crowd Counting and Localization</a><br />
      Dongze Lian, Jing Li, Jia Zheng, <strong>Weixin Luo</strong>, Shenghua Gao<br />
      CVPR 2019 
    </div>
  </div>
  <!--------------------------------------------------------------------------->
  
  
  <!--------------------------------------------------------------------------->
  <!--luowx2019aaai-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luowx2019aaai">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luowx2019aaai']);" href="https://www.researchgate.net/profile/Ziheng_Zhang3/publication/333668241_RGBD_Based_Gaze_Estimation_via_Multi-task_CNN/links/5cfccefea6fdccd1308d9b01/RGBD-Based-Gaze-Estimation-via-Multi-task-CNN.pdf">RGBD Based Gaze Estimation via Multi-task CNN</a><br />
      Dongze Lian, Ziheng Zhang, <strong>Weixin Luo</strong>, lina hu, Minye Wu, Zechao Li, Jingyi Yu, Shenghua Gao.<br />
      AAAI 2019
    </div>
  </div>
  <!--------------------------------------------------------------------------->
  
  <!--------------------------------------------------------------------------->
  <!--luowx2018cvpr1-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luowx2018cvpr1">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luowx2018cvpr1']);" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Liu_Future_Frame_Prediction_CVPR_2018_paper.pdf">Future Frame Prediction for Anomaly Detection â€“ A New Baseline</a><br />
      Wen Liu*, <strong>Weixin Luo*</strong>, Shenghua Gao.<br />
      CVPR 2018 /
      <a href="https://github.com/StevenLiuWen/ano_pred_cvpr2018"> code </a>
    </div>
  </div>
  <!--------------------------------------------------------------------------->
  
  <!--------------------------------------------------------------------------->
  <!--luowx2018cvpr2-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luowx2018cvpr">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luowx2018cvpr2']);" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Face_Aging_With_CVPR_2018_paper.pdf">Face Aging with Identity-Preserved Conditional Generative Adversarial Network</a><br />
      Zongwei Wang, Xu Tang, <strong>Weixin Luo</strong>, Shenghua Gao.<br />
      CVPR 2018 /
      <a href="https://github.com/dawei6875797/Face-Aging-with-Identity-Preserved-Conditional-Generative-Adversarial-Networks"> code </a>
    </div>
  </div>
  <!--------------------------------------------------------------------------->
  
  <!--------------------------------------------------------------------------->
  <!--luowx2018tnnls-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luowx2018tnnls">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luowx2018tnnls']);" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8454246">Multi-view Multi-task Gaze Prediction with Deep Convolutional Neural Networks.</a><br />
      Dongze Lian, Shenghua Gao, Lina Hu, <strong>Weixin Luo</strong>, Yanyu Xu, Lixin Duan, Jingyi Yu.<br />
      TNNLS 2018
    </div>
  </div>
  <!--------------------------------------------------------------------------->
  
  <!--------------------------------------------------------------------------->
  <!--luowx2017iccv-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luowx2017iccv">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luowx2017iccv']);" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Luo_A_Revisit_of_ICCV_2017_paper.pdf">A Revisit of Sparse Coding Based Anomaly Detection in Stacked RNN
Framework</a><br />
      <strong>Weixin Luo*</strong>, Wen Liu*, Shenghua Gao.<br />
      ICCV 2017 /
      <a href="https://github.com/StevenLiuWen/sRNN_TSC_Anomaly_Detection"> code </a>
    </div>
  </div>
  <!--------------------------------------------------------------------------->
  
  <!--------------------------------------------------------------------------->
  <!--luowx2017icme-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luowx2017icme">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luowx2017icme']);" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8019325">Remembering History with Convolutional LSTM for Anomaly Detection</a><br />
      <strong>Weixin Luo*</strong>, Wen Liu*, Shenghua Gao.<br />
      ICME 2017 (oral)/
      <a href="https://github.com/zachluo/convlstm_anomaly_detection"> code </a>
    </div>
  </div>
  <!--------------------------------------------------------------------------->
  
  <!--------------------------------------------------------------------------->
  <!--luowx2016aaai-->
  <!--------------------------------------------------------------------------->
  <div class="paper" id="luowx2016aaai">
    <div class="wide">
      <a class="paper" onclick="_gaq.push(['_trackEvent', 'Pub', 'Download', 'luowx2016aaai']);" href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11946/11869">Analysis-Synthesis Dictionary Learning for Universality-Particularity Representation Based Classification</a><br />
      Meng Yang, Weiyang Liu, <strong>Weixin Luo</strong>, Linlin Shen.<br />
      AAAI 2016 
    </div>
  </div>
  <!--------------------------------------------------------------------------->
</div>

</div>

</div><!-- close page div -->

<div style="clear:both;">
  <p align="right"><font size="2"><a href="http://jonbarron.info">I like this website</a></font></p><br />
</div>

<script xml:space="preserve" language="JavaScript">
hideallbibs();
hideallabs();
</script>

</body>

</html>
